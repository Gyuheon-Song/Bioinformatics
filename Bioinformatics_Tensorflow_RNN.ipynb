{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gyuheon-Song/Bioinformatics/blob/main/Bioinformatics_Tensorflow_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use this tutorial"
      ],
      "metadata": {
        "id": "IrRu54YhSUxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This tutorial utilizes a Colab notebook , which is an interactive computational enviroment that combines live code, visualizations, and explanatory text. To run this notebook, you may first need to **sign in with your Google account** and make a copy by choosing **File > Save a Copy in Drive** from the menu bar (may take a few moments to save).\n",
        "\n",
        "The most powerful feature of google colab is the ability to use cloud GPU for free. At first turn on the GPU from **Runtime > Change Runtime Type > Hardware Acceleration**. Then **click on the Connect button located at the top right of the page** to assign server resources.\n",
        "\n",
        "If you are connected to a runtime, you need to **upload the sample data** to the server. Click on the **'Files'** tab on the left side of the page and press the **'upload'** button at the top to upload the data. Please note that if the connection is disconnected, all the data will be deleted, so please be careful.\n",
        "\n",
        "The notebook is organized into a series of cells. You can modify the Python command and execute each cell as you would a Jupyter notebook. To execute each of the cells, **click on the black run button located at the top left of the code block.**\n",
        "\n"
      ],
      "metadata": {
        "id": "q12dStc4ScBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Background"
      ],
      "metadata": {
        "id": "YVtIIVd7c0yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, you will train a **recurrent neural network (RNN)** model that can discover **Cfp1 endonuclease binding motifs** (a component of CRISPR system) binding sites in given DNA sequences."
      ],
      "metadata": {
        "id": "kimnOp9Ic5rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Setup the environment"
      ],
      "metadata": {
        "id": "AnUtULLzM4Jc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "zPtv43XmKkdh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Set hyperparameters"
      ],
      "metadata": {
        "id": "chtuukv0NAXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.01\n",
        "TOTAL_EPOCH = 30\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "N_INPUT = 4\n",
        "N_STEP = 34\n",
        "N_HIDDEN = 32\n",
        "N_CLASS = 2\n",
        "\n",
        "DISPLAY_STEP = 200"
      ],
      "metadata": {
        "id": "M6XBgE2EIqma"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load datasets"
      ],
      "metadata": {
        "id": "wxzH8EgxNDw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_dataset(dataset_file_path):\n",
        "    \"\"\"\n",
        "    read and parse given sequence dataset, line by line\n",
        "    \"\"\"\n",
        "    dna_mapping = {\"A\":0, \"T\":1, \"G\":2, \"C\":3}\n",
        "    data = list()\n",
        "    labels = list()\n",
        "\n",
        "    with open(dataset_file_path) as DATA:\n",
        "        num_lines = 0\n",
        "        for line in DATA:\n",
        "            num_lines += 1\n",
        "            sequence, activity = line.strip().split(\"\\t\")\n",
        "            mapped_dna_string = [dna_mapping[k] for k in sequence]\n",
        "            data.append(mapped_dna_string)\n",
        "            if int(activity) == 1:\n",
        "                labels.append([0.0, 1.0])\n",
        "            else:\n",
        "                labels.append([1.0, 0.0])\n",
        "\n",
        "    return data, labels, num_lines\n",
        "\n",
        "def load_next_batch(train_x, train_y, batch_size, step):\n",
        "    \"\"\"\n",
        "    prepare batch data\n",
        "    \"\"\"\n",
        "    start = batch_size * step\n",
        "    end = start + batch_size\n",
        "    batch_xs = train_x[start:end]\n",
        "    batch_ys = train_y[start:end]\n",
        "\n",
        "    return batch_xs, batch_ys\n"
      ],
      "metadata": {
        "id": "1cDJ7lhPKmgo"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/\"\n",
        "\n",
        "train_file_path = data_dir + \"content/sample_data/cfp1_train.txt\"  # write your own file path\n",
        "test_file_path = data_dir + \"content/sample_data/cfp1_test.txt\"\n",
        "\n",
        "train_x, train_y, num_train = load_dataset(train_file_path)\n",
        "\n",
        "train_x, train_y = shuffle(train_x, train_y)\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)"
      ],
      "metadata": {
        "id": "CaxQp_-1Kmrn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.  Construct the model"
      ],
      "metadata": {
        "id": "-IJr7isdNIEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(N_INPUT, N_HIDDEN))\n",
        "model.add(LSTM(N_HIDDEN, return_sequences=False))\n",
        "model.add(Dense(N_CLASS, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VNCCoAFpKmxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92d95e7-f46a-4da3-8ea0-3b60e802364d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 8)           32        \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 8)                 544       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 594 (2.32 KB)\n",
            "Trainable params: 594 (2.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Train the model"
      ],
      "metadata": {
        "id": "jGD0lS7cNMDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=TOTAL_EPOCH)"
      ],
      "metadata": {
        "id": "esYz1yLYKm2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd372eef-808d-4beb-c536-c4763ddc7087"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "24/24 [==============================] - 4s 19ms/step - loss: 0.6815 - accuracy: 0.5323\n",
            "Epoch 2/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6191 - accuracy: 0.6647\n",
            "Epoch 3/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5831 - accuracy: 0.6927\n",
            "Epoch 4/30\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5506 - accuracy: 0.7157\n",
            "Epoch 5/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.5254 - accuracy: 0.7347\n",
            "Epoch 6/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5077 - accuracy: 0.7480\n",
            "Epoch 7/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4912 - accuracy: 0.7613\n",
            "Epoch 8/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4692 - accuracy: 0.7673\n",
            "Epoch 9/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4509 - accuracy: 0.7903\n",
            "Epoch 10/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4253 - accuracy: 0.8007\n",
            "Epoch 11/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4156 - accuracy: 0.8043\n",
            "Epoch 12/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4192 - accuracy: 0.8030\n",
            "Epoch 13/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4039 - accuracy: 0.8120\n",
            "Epoch 14/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3932 - accuracy: 0.8180\n",
            "Epoch 15/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3677 - accuracy: 0.8397\n",
            "Epoch 16/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3694 - accuracy: 0.8353\n",
            "Epoch 17/30\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3686 - accuracy: 0.8380\n",
            "Epoch 18/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3733 - accuracy: 0.8353\n",
            "Epoch 19/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3453 - accuracy: 0.8523\n",
            "Epoch 20/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3423 - accuracy: 0.8540\n",
            "Epoch 21/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3288 - accuracy: 0.8613\n",
            "Epoch 22/30\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.3337 - accuracy: 0.8680\n",
            "Epoch 23/30\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.3299 - accuracy: 0.8643\n",
            "Epoch 24/30\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.3232 - accuracy: 0.8753\n",
            "Epoch 25/30\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.3223 - accuracy: 0.8703\n",
            "Epoch 26/30\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.2975 - accuracy: 0.8837\n",
            "Epoch 27/30\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.3027 - accuracy: 0.8780\n",
            "Epoch 28/30\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2931 - accuracy: 0.8843\n",
            "Epoch 29/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3143 - accuracy: 0.8730\n",
            "Epoch 30/30\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3059 - accuracy: 0.8730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf7f98c5c30>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluate the model"
      ],
      "metadata": {
        "id": "Kh7xfIBbNO6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_xs, test_ys, num_test = load_dataset(test_file_path)\n",
        "test_xs = np.array(test_xs)\n",
        "test_ys = np.array(test_ys)\n",
        "\n",
        "_, accuracy = model.evaluate(test_xs, test_ys, batch_size=BATCH_SIZE)\n",
        "print(\"Avg. accuracy: %.5f\" % accuracy)"
      ],
      "metadata": {
        "id": "mYNZEttsJreq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44f2917-abf4-4ae4-ce46-78a62a84fb5a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 10ms/step - loss: 0.3281 - accuracy: 0.8721\n",
            "Avg. accuracy: 0.87209\n"
          ]
        }
      ]
    }
  ]
}